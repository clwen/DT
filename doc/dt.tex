\title{DTour Data Analysis}
\author{
    Chung-Lin Wen \\
    Research Intern, Disney Research Boston \\
}
\date{\today}

\documentclass[12pt]{article}
\usepackage{graphicx}

\begin{document}
\maketitle

\begin{abstract}

In this report, I will explain what progress I have made on the DTour project. The work can be summarized in three parts: tarnsferring GPS fixes data to venue attendance information, clustering demographic data and venue attendance data, and using demographic data to predict the venue attendace behaviour.
\end{abstract}

\section{Introduction}

DTour is a project that aim at providing better them park experience by applying load-balancing techniques. To achieve this, several researches have to be done. First, to understand the tourists behaviour in the theme parks, we conducted experiments by collecting tourists locations, in the form of GPS fixes. The noisy GPS fixes need to be transfer to venue attendance information for further usage. This compose the first part of our work.

Second, it will be helpful if we can classify groups of tourists into certain "personas", so that we know which venues they will most likely to be interested in. We can further utilized this knowledge to deliever the most relevant incentives while avoid spamming tourits with unhelpful coupous.

Finally, similar to the motivation of clustering, it would be even more desirable if we can use some characteristics to predict the venue attendance behaviour. By now, the system uses demographic data to predict the venue attendance behaviour. However, it can also be extended to use other combination for the prediction. For instance, demographic data can be combined with real-time venue attendance data to predict the tourists behaviour in the rest of the day.

In the following sections, we will discuss each part respectively. The report then concluded with future works.

\section{GPS to Venue Attendance}\label{gps_venue}

The GPS data is recorded in longitude and latitude. It has to be transofmed into venue attendacne information before it can be used for clustering and prediction. We also get better insights on how tourists travel in the park by conducting the transfering.

The basic idea behind our algorithm is to grow an area $A$ from the known "geofence" $G$ by a distance $l$, which mark the venue location and area. We then traverse each GPS fixes, see if they are lying inside the grown area $A_v$ of certain venue or not. We then examine whether there are consecutive GPS fixes that spent a period $t$ more than a pre-defined threshold $\tau$, if so, we conclude the gruop attended the venue. In the current setting, we found that parameters $15$ meters for $l$ and $3$ minutes for $\tau$ yields results that match our expectation. Figure \ref{fixes-fences} illustrates the GPS fixes and Geofences. Currently, $1369$ points and $21$ venues from 2011 experiment are investigated.  

\begin{figure}
\centering
    \includegraphics[scale=0.5]{figs/fixes-fences.eps}
\caption{GPS fixes and Geofences in the visualization program}
\label{fixes-fences}
\end{figure}

\section{Clustering}\label{clustering}
Demographic data and venue attedance are then clustered. We encode the demographic data and venue attendence into numeric vectors with each column normalized from $0$ to $1$. We then applied the KMeans clustering algorithm \cite{Lloyd82} to the data. We determine the optimal $k$ by plotting the distortion function and choose several $k$ near the elbow point, where the marginal decrease of distortion function become smaller. For example, Figure \ref{kmeans-k} is an instance of distortion function in different $k$ plotted. In this example, the figure suggest that optimal $k$ may be around $3$.

\begin{figure}
\centering
    \includegraphics[scale=0.55]{figs/distortion.eps}
\caption{Distortion function for diffrent $k$ in KMeans algorithm}
\label{kmeans-k}
\end{figure}

However, in some fields, Euclidean distance doesn't make sense. For instance, in the nationality field, if we encode USA by $1$, China for $2$, and UK for $3$, doesn't mean that USA is "closer" to China than USA to UK. Therefore, a density-based algorithm DBSCAN \cite{Ester96} are also applied. In DBSCAN, we define similar function for fields (in 2011 data, nationality and resorts tourists living) that don't apply to Euclidean distance as the following: return $0$ if they are identical, else return $1$.

Both the implementations of KMeans and DBSCAN (also the classification algorithms of Section \ref{prediction}) use the Python library Scikits Learn \cite{sklearn}.

\section{Prediction}\label{prediction}

In the current setting, demographic data are used to predict the venue attendance. For each venue and a given set of demographic data from a specific group, we train a classfier to predict the group will attend the venue or not. Four classification algorithms are used: Naive Bayes, SVM \cite{Cortes95}, Decision Tree, and Random Forest \cite{Breiman01}. We average the precision of each algorithm across each venue and the result can be summarized in Table \ref{class-accu}. All the accuracies are calculated under a 10-fold k-fold cross validation.

As we can see from the result, SVM yields the best precision and all of the classifiers generate significantly better result than base-line, which is around $50\%$. 

\begin{table}
\begin{center}
    \begin{tabular}{ | c | c | }
        \hline
        \textbf {Classfier} & \textbf{Avg. Accuracy} \\ \hline
        \hline
        Naive Bayes     & 80.62\% \\ \hline
        SVM             & 86.28\% \\ \hline
        Decision Tree   & 75.41\% \\ \hline
        Random Forest   & 85.11\% \\ \hline
    \end{tabular}
\caption{Accuracy of different classification algorithms}
\label{class-accu}
\end{center}
\end{table}

Accuracies for different venue are also not identical. The accuraries ranging from $74.76\%$ to $96.23\%$ as shown in the Figure \ref{venue-accu}. This is not a surprising result, since the prediction power of demographic are not the same for different venue.

\begin{table}
\begin{center}
    \begin{tabular}{ | c | c | }
        \hline
        \textbf {Venue} & \textbf{Avg. Accuracy} \\ \hline
        \hline
        Aladdin The Flying Carpet Over Agrabah & 74.76\% \\ \hline
        Animagique & 94.74\% \\ \hline
        Armageddon & 89.49\% \\ \hline
        Art of Disney Animation & 81.72\% \\ \hline
        Backlot Express & 84.16\% \\ \hline
        Cars Quatre Roues Rallye & 87.4\% \\ \hline
        Cinemagique & 93.72\% \\ \hline
        Crush\'s Coaster & 79.98\% \\ \hline
        En Coulisse \& Legends of Hollywood & 88.94\% \\ \hline
        Food \& Beverage & 80.85\% \\ \hline
        Front Gate & 91.96\% \\ \hline
        Guest Services & 78.5\% \\ \hline
        Moteurs Action & 76.51\% \\ \hline
        RC Racer & 90.12\% \\ \hline
        Rock\'n Roller Coaster & 90.68\% \\ \hline
        Slinky Dog Zig Zag Spin & 88.34\% \\ \hline
        Snitch Live, Playhouse Disney & 94.62\% \\ \hline
        Studio Tram Tour & 81.03\% \\ \hline
        Studios Store & 96.23\% \\ \hline
        Tower of Terror & 76.1\% \\ \hline
        Toy Soldiers Parachute Drop & 91.09\% \\ \hline
    \end{tabular}
\caption{Accuracy of different venues under SVM classification}
\label{venue-accu}
\end{center}
\end{table}

\section{Future Work}\label{future_work}

Several possible future directions are listed here. First, to reduce the noise in GPS data we acquired, some noise filtering techniques can be applied, such as temporal Kalman filter \cite{Welch95}.

Second, some heuristics can be used to improve the current GPS to attendance method. For instance, by observation, the venue attendance are not necessarily formed by totally consecutive point-in-polygon fixes due to the noise. Therefore, we can improve the method by allowing a gap of one or two points that are not in the polygon but still counted as consecutive.

In addition, we can use more sophiscated algorithm to model the GPS to venue transformation, such as Hidden Markov Model (HMM).

Another interesting experiment to do is to use feature selection algorithms to discover some most useful features when predicting a certain venue. For instance, if we know couples are most likely to attend "Tower of Terror", while families with children under 12 are most likely to attend "Toy Soldiers Parachute Drop", we can use this knowledge while distributing coupons without explicitly doing the machine learning or clustering in a real-time fashion.

Finally the current experiments are based on 2011 data, it would be desirable to do the experiment on other data (currently 2012 are also availble). 

\bibliographystyle{abbrv}
\bibliography{reference}

\end{document}
